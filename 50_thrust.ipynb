{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/50_thrust.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qF1uQPZBNA3"
   },
   "source": [
    "# Thrust Library\n",
    "\n",
    "According to nVidia:\n",
    "\n",
    "Thrust is a C++ template library for CUDA based on the Standard Template Library (STL). Thrust allows you to implement high performance parallel applications with minimal programming effort through a high-level interface that is fully interoperable with CUDA C.\n",
    "\n",
    "Thrust provides a rich collection of data parallel primitives such as scan, sort, and reduce, which can be composed together to implement complex algorithms with concise, readable source code. By describing your computation in terms of these high-level abstractions you provide Thrust with the freedom to select the most efficient implementation automatically. As a result, Thrust can be utilized in rapid prototyping of CUDA applications, where programmer productivity matters most, as well as in production, where robustness and absolute performance are crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXs5A0DQESu-"
   },
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5uSEBn2_Y_D",
    "outputId": "6bafdeac-b79d-4ab1-d19d-7444fd080cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing thrust_sum.cu\n"
     ]
    }
   ],
   "source": [
    "%%file thrust_sum.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <thrust/device_vector.h>\n",
    "\n",
    "void cpu_sum(int *x, int n)\n",
    "{\n",
    "    int result = 0;\n",
    "    for(unsigned int i=0; i < n; ++i) { \n",
    "        result += x[i];\n",
    "    }\n",
    "    printf(\"CPU Sum is %d \\n\", result);\n",
    "}\n",
    "\n",
    "void gpu_sum(int *x, int n)\n",
    "{\n",
    "\n",
    "    thrust::device_vector<int> d_vec(n,0); // initialize all n integers of a device_vector to 0\n",
    "\n",
    "    for(unsigned int i = 0; i < n; ++i){\n",
    "        d_vec[i] = x[i];\n",
    "    }\n",
    "\n",
    "    int t_sum = thrust::reduce(d_vec.begin(), d_vec.end(), (int) 0, thrust::plus<int>());\n",
    "    printf(\"GPU (thrust) Sum is %d \\n\", t_sum);\n",
    "}\n",
    "\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int h[] = {10, 1, 8, -1, 0, -2, 3, 5, -2, -3, 2, 7, 0, 11, 0, 2};\n",
    "\n",
    "    int size = sizeof(h);\n",
    "    int count = size/sizeof(int);\n",
    "\n",
    "    cpu_sum(h, count);\n",
    "    gpu_sum(h, count);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt3YAkBnBW-f",
    "outputId": "494c9050-38ca-4b10-8467-727dbe54633d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 23 19:30:25 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPIQoi99EE7r",
    "outputId": "74e477ed-a027-4943-dc45-5123014a6e25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Sum is 41 \n",
      "GPU (thrust) Sum is 41 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_SUFF=35\n",
    "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./thrust_sum.cu -o thrust_sum\n",
    "./thrust_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1LqTI_TEawo"
   },
   "source": [
    "## SAXPY\n",
    "\n",
    "**SAXPY** stands for “Single-Precision A·X Plus Y”. It is a function in the standard Basic Linear Algebra Subroutines (BLAS)library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMW8FHyMEYO9",
    "outputId": "0ae3df8e-fc18-43ba-9252-e6bbe125ca1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing thrust_saxpy.cu\n"
     ]
    }
   ],
   "source": [
    "%%file thrust_saxpy.cu\n",
    "\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <thrust/device_vector.h>\n",
    "#include <iostream>\n",
    "\n",
    "struct saxpy_functor\n",
    "{\n",
    "    const float a;\n",
    "    saxpy_functor(float _a) : a(_a) {}\n",
    "\n",
    "    __host__ __device__\n",
    "    float operator()(const float& x, const float& y) const \n",
    "    {\n",
    "        return a * x + y;\n",
    "    }\n",
    "};\n",
    "\n",
    "thrust::device_vector<float> saxpy_fast(float A, thrust::device_vector<float>& X, thrust::device_vector<float>& Y)\n",
    "{   \n",
    "    // SAXPY stands for “Single-Precision A·X Plus Y”\n",
    "    // result <- A * X + Y\n",
    "    thrust::device_vector<float> result(X.size());\n",
    "    thrust::transform(X.begin(), X.end(), Y.begin(), result.begin(), saxpy_functor(A));\n",
    "\n",
    "    return result;\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "    // allocate two device_vectors with 5 elements\n",
    "    thrust::device_vector<float> X(5);\n",
    "    thrust::device_vector<float> Y(5);\n",
    "\n",
    "    // initialize the arrays to 0,1,2,3,4\n",
    "    thrust::sequence(X.begin(), X.end());\n",
    "    thrust::sequence(Y.begin(), Y.end());\n",
    "\n",
    "    auto result = saxpy_fast(100, X, Y);\n",
    "\n",
    "    // print results\n",
    "    for(int i = 0; i < result.size(); i++)\n",
    "        std::cout << \"result[\" << i << \"] = \" << result[i] << std::endl;\n",
    "}\n",
    "\n",
    "// output\n",
    "// result[0] = 0\n",
    "// result[1] = 101\n",
    "// result[2] = 202\n",
    "// result[3] = 303\n",
    "// result[4] = 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGbukvBnEuzH",
    "outputId": "1faa4675-9208-463e-81ab-7a04b7fd0f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result[0] = 0\n",
      "result[1] = 101\n",
      "result[2] = 202\n",
      "result[3] = 303\n",
      "result[4] = 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_SUFF=35\n",
    "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./thrust_saxpy.cu -o thrust_saxpy\n",
    "./thrust_saxpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1xMbT9yE1Jz"
   },
   "source": [
    "## Additional reading\n",
    "\n",
    "[Official Quick Start Guide](https://docs.nvidia.com/cuda/archive/11.0/pdf/Thrust_Quick_Start_Guide.pdf)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUmJql4UwWQUzH1dCftb3R",
   "include_colab_link": true,
   "name": "example50_thrust.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
