{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad38dd37",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/10_intro_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609",
   "metadata": {
    "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609"
   },
   "source": [
    "# Introduction - Syntax sugar \n",
    "\n",
    "When you run a command with \n",
    "\n",
    "- `!`  it directly executes a bash command in a **subshell**.\n",
    "\n",
    "- `%`  it executes one of the magic commands defined in IPython.\n",
    "\n",
    "- `%% my_native_language` defines the language used to interpret the cell\n",
    "\n",
    "Some of the magic commands defined by IPython deliberately mirror bash commands, but they differ in the implementation details.\n",
    "\n",
    "For example, running the !cd bash command does not persistently change your directory, because it runs in a temporary subshell. However, running the %cd magic command will persistently change your directory:\n",
    "\n",
    "```.sh\n",
    "!pwd\n",
    "# /content\n",
    "\n",
    "!cd sample_data/\n",
    "!pwd\n",
    "# /content\n",
    "\n",
    "%cd sample_data/\n",
    "!pwd\n",
    "# /content/sample_data\n",
    "```\n",
    "\n",
    "Reference <https://ipython.readthedocs.io/en/stable/interactive/magics.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dhrB0IVgfK_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dhrB0IVgfK_",
    "outputId": "b413eb49-959f-4a7f-c822-789fad87d92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.43656366 14.7781122  40.17107385]\n",
      "env: MY_VARIABLE=123\n",
      "/home/grzegorz/GITHUB/CUDA/gpu_colab\n",
      "my shell variable \n"
     ]
    }
   ],
   "source": [
    "# an example of mixing python an shell in one cell\n",
    "\n",
    "# this is python (default interpreter)\n",
    "import numpy as np\n",
    "print(2*np.exp([1,2,3])) \n",
    "\n",
    "# this is bash shell\n",
    "%env  MY_VARIABLE=123 \n",
    "!pwd\n",
    "!echo \"my shell variable ${123}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968277ee-c022-4ecc-8b46-9452e2c4b670",
   "metadata": {
    "id": "968277ee-c022-4ecc-8b46-9452e2c4b670"
   },
   "source": [
    "## Get the material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
    "outputId": "84bb956a-575c-4d21-94e1-82baa8437d6c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'gpu_colab' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ggruszczynski/gpu_colab.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pjHRMGHu2l4n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjHRMGHu2l4n",
    "outputId": "982ec752-1845-4145-8815-1675f05e1eb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_intro_setup.ipynb\t\t       a.cpp\t      pdfy\n",
      "20_vector_add.ipynb\t\t       a.out\t      README.md\n",
      "30_element_wise_matrix_add.ipynb       experimental   requirements.txt\n",
      "30_matrix_matrix_multiplication.ipynb  gpu_colab      solutions\n",
      "40_parallel_reduction.ipynb\t       hello\t      src\n",
      "50_thrust.ipynb\t\t\t       hello.cpp      to_pdf_1by1.sh\n",
      "60_python_cuda_intro.ipynb\t       hello_cuda\n",
      "70_heat_diffusion2D.ipynb\t       hello_cuda.cu\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
    "outputId": "1ecd3178-f6a2-4d10-b55b-97974fb7faad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'gpu_colab/code_samples'\n",
      "/home/grzegorz/GITHUB/CUDA/gpu_colab\n"
     ]
    }
   ],
   "source": [
    "%cd gpu_colab/code_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f",
   "metadata": {
    "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f"
   },
   "source": [
    "## Create a file, compile & run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pMoR9ZcTXlEQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMoR9ZcTXlEQ",
    "outputId": "d72181d7-5190-4c07-a854-c5b78c51a18f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file hello.cpp\n",
    "#include <iostream>\n",
    "\n",
    "int main() {\n",
    "    std::cout << \"Hello World!\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "HaXyn0NFacCN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HaXyn0NFacCN",
    "outputId": "6660bcc0-51d1-4d36-c65b-51afc817d9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===print working directory and its content===\n",
      "/home/grzegorz/GITHUB/CUDA/gpu_colab\n",
      "10_intro_setup.ipynb\n",
      "20_vector_add.ipynb\n",
      "30_element_wise_matrix_add.ipynb\n",
      "30_matrix_matrix_multiplication.ipynb\n",
      "40_parallel_reduction.ipynb\n",
      "50_thrust.ipynb\n",
      "60_python_cuda_intro.ipynb\n",
      "70_heat_diffusion2D.ipynb\n",
      "a.cpp\n",
      "a.out\n",
      "experimental\n",
      "gpu_colab\n",
      "hello\n",
      "hello.cpp\n",
      "hello_cuda\n",
      "hello_cuda.cu\n",
      "pdfy\n",
      "README.md\n",
      "requirements.txt\n",
      "solutions\n",
      "src\n",
      "to_pdf_1by1.sh\n",
      "===execute the program===\n",
      "Hello World!"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "g++ hello.cpp -o hello\n",
    "echo \"===print working directory and its content===\"\n",
    "pwd\n",
    "ls\n",
    "echo \"===execute the program===\"\n",
    "./hello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adUrXDBVdhjh",
   "metadata": {
    "id": "adUrXDBVdhjh"
   },
   "source": [
    "## cpp (auto) magic \n",
    "\n",
    "This section explains how to create a wrapper for your cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hpCwJPSRd3J1",
   "metadata": {
    "id": "hpCwJPSRd3J1"
   },
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ty9_RQd41P",
   "metadata": {
    "id": "18ty9_RQd41P"
   },
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def cpp(line, cell):\n",
    "  with open('a.cpp', 'w') as f:\n",
    "    f.write(cell)\n",
    "  !g++ a.cpp\n",
    "  !./a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Yt-qkdx5d7gP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yt-qkdx5d7gP",
    "outputId": "1c8a05a8-8b0c-452a-de74-826800390ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!"
     ]
    }
   ],
   "source": [
    "%%cpp\n",
    "#include <iostream>\n",
    "int main() {\n",
    "    std::cout << \"Hello World!\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ccedQXcd-Ph",
   "metadata": {
    "id": "4ccedQXcd-Ph"
   },
   "outputs": [],
   "source": [
    "cpp_header = \"\"\"\n",
    "#include <iostream> \n",
    "#include <string>\n",
    "#include <iterator> \n",
    "#include <utility> \n",
    "#include <map>\n",
    "using namespace std;\n",
    "\"\"\"\n",
    "\n",
    "@register_cell_magic\n",
    "def cpp(line, cell):\n",
    "  if ' main()' not in cell:\n",
    "    cell = \"int main(){\" + cell + \"}\"\n",
    "  with open('a.cpp', 'w') as f:\n",
    "    f.write(cpp_header + cell)\n",
    "  !g++ a.cpp\n",
    "  !./a.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "EpDK39cDeGeZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpDK39cDeGeZ",
    "outputId": "d7a9a1ab-15b6-4139-c98d-0f71bb888da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!"
     ]
    }
   ],
   "source": [
    "%%cpp\n",
    "std::cout << \"Hello World!\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "v6301a-aeHwj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6301a-aeHwj",
    "outputId": "c9acde83-edb6-428f-ee64-64aa0a5c6169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01234\n",
      "100 lat!\n"
     ]
    }
   ],
   "source": [
    "%%cpp\n",
    "for(int i=0; i<5; i++) {\n",
    "    cout << i;\n",
    "}\n",
    "\n",
    "cout << endl;\n",
    "pair <int, string> PAIR1; \n",
    "\n",
    "PAIR1.first = 100; \n",
    "PAIR1.second = \"lat!\" ; \n",
    "\n",
    "cout << PAIR1.first << \" \"; \n",
    "cout << PAIR1.second << endl; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707",
   "metadata": {
    "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707"
   },
   "source": [
    "# Activate GPU\n",
    "\n",
    "- To get access to a GPU, click on the *Runtime* menu and select *Change runtime type*. Choose GPU as a Hardware accelerator. It might take a minute for your notebook to connect to a GPU.\n",
    "- To check whether a GPU has been connected to your session, run the code cell below with the ``!nvidia-smi`` command by hitting ``SHIFT-ENTER`` on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
    "outputId": "103c6174-f72d-455a-ecd4-28b971143354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 16 17:39:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   57C    P5    31W / 250W |   1473MiB /  8192MiB |     14%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1703      G   /usr/lib/xorg/Xorg                 96MiB |\n",
      "|    0   N/A  N/A      2624      G   /usr/lib/xorg/Xorg                684MiB |\n",
      "|    0   N/A  N/A      2819      G   /usr/bin/gnome-shell               66MiB |\n",
      "|    0   N/A  N/A      3712      G   ...RendererForSitePerProcess        3MiB |\n",
      "|    0   N/A  N/A      8175      G   ...features=BackForwardCache       10MiB |\n",
      "|    0   N/A  N/A      8543      G   ...957248867340528764,131072      237MiB |\n",
      "|    0   N/A  N/A     13016      G   ...AAAAAAAAA= --shared-files       35MiB |\n",
      "|    0   N/A  N/A     14339      G   ...b/thunderbird/thunderbird      121MiB |\n",
      "|    0   N/A  N/A     15643      G   ...RendererForSitePerProcess      169MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dOjw-YYKgFAk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOjw-YYKgFAk",
    "outputId": "849b6f4f-a50b-4dea-b281-87595f734c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello_cuda.cu\n"
     ]
    }
   ],
   "source": [
    "%%file hello_cuda.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "// functions qualifers:\n",
    "// __global__ launched by CPU on device (must return void)\n",
    "// __device__ called from other GPU functions (never CPU)\n",
    "// __host__ can be executed by CPU\n",
    "// (can be used together with __device__)\n",
    "\n",
    "// kernel launch:\n",
    "// f_name<<<blocks,threads_per_block>>>(p1,... pN)\n",
    "\n",
    "__global__ void print_from_gpu(void) {\n",
    "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
    "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
    "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    printf(\"Hello World from host!\\n\");\n",
    "\n",
    "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
    "    cudaDeviceSynchronize();\n",
    "    printf(\"-------------------------------\\n\");\n",
    "    dim3 grid_dim(2,1,1);\n",
    "    dim3 block_dim(3,1,1);\n",
    "    print_from_gpu<<<grid_dim, block_dim>>>();  // <<<blocks, threads_per_block>>>\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd",
   "metadata": {
    "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd"
   },
   "source": [
    "## Check version of your GPU card\n",
    "if you received an older gpu like Tesla K80 (check the output of `!nvidia-smi` command) add the `-gencode arch=compute_35,code=sm_35` flags to nvcc compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "CM8yJ2s6sUF9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CM8yJ2s6sUF9",
    "outputId": "e3ca9a9c-ff46-4d6a-ce5c-4c6eff3df473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from host!\n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
      "-------------------------------\n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CUDA_SUFF=70\n",
    "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./hello_cuda.cu -o hello_cuda\n",
    "./hello_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Um57DFCosVPp",
   "metadata": {
    "id": "Um57DFCosVPp"
   },
   "source": [
    "## if you were lucky to get a more recent gpu (like Tesla T4)...\n",
    "\n",
    "you can install a python wrapper to run `%%cu` cells directly\n",
    "\n",
    "```.sh\n",
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
    "%load_ext nvcc_plugin\n",
    "```\n",
    "\n",
    "then,\n",
    "\n",
    "```\n",
    "%%cu \n",
    "\n",
    "your cell with cuda code...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2wOeFnMsFc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2wOeFnMsFc8",
    "outputId": "0f4338e9-ba63-4a56-b871-70b7299b1add"
   },
   "outputs": [],
   "source": [
    "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "XljRG_pmsKir",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XljRG_pmsKir",
    "outputId": "f4a45c8a-1140-4872-aeb4-930b0629e333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory /home/grzegorz/GITHUB/CUDA/gpu_colab/src already exists\n",
      "Out bin /home/grzegorz/GITHUB/CUDA/gpu_colab/result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "WEJ5EW8tsBq7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEJ5EW8tsBq7",
    "outputId": "22679a9b-842c-427e-8833-66d058c3e874",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from host!\n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
      "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cu \n",
    "\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void print_from_gpu(void) {\n",
    "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
    "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
    "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
    "}\n",
    "\n",
    "int main(void) {\n",
    "    printf(\"Hello World from host!\\n\");\n",
    "\n",
    "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "intro_setup.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
