{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/10_intro_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609",
      "metadata": {
        "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609"
      },
      "source": [
        "# Introduction - Syntax sugar\n",
        "\n",
        "When you run a command with\n",
        "\n",
        "- `!`  it directly executes a bash command in a **subshell**.\n",
        "\n",
        "- `%`  it executes one of the magic commands defined in IPython.\n",
        "\n",
        "- `%% my_native_language` defines the language used to interpret the cell\n",
        "\n",
        "Some of the magic commands defined by IPython deliberately mirror bash commands, but they differ in the implementation details.\n",
        "\n",
        "For example, running the !cd bash command does not persistently change your directory, because it runs in a temporary subshell. However, running the %cd magic command will persistently change your directory:\n",
        "\n",
        "```.sh\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "!cd sample_data/\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "%cd sample_data/\n",
        "!pwd\n",
        "# /content/sample_data\n",
        "```\n",
        "\n",
        "Reference <https://ipython.readthedocs.io/en/stable/interactive/magics.html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5dhrB0IVgfK_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dhrB0IVgfK_",
        "outputId": "dd342919-3dde-4351-933f-2e2138071802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.43656366 14.7781122  40.17107385]\n",
            "env: MY_VARIABLE=123\n",
            "/content\n",
            "my shell variable 23\n"
          ]
        }
      ],
      "source": [
        "# an example of mixing python an shell in one cell\n",
        "\n",
        "# this is python (default interpreter)\n",
        "import numpy as np\n",
        "print(2*np.exp([1,2,3]))\n",
        "\n",
        "# this is bash shell\n",
        "%env  MY_VARIABLE=123\n",
        "!pwd\n",
        "!echo \"my shell variable ${123}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968277ee-c022-4ecc-8b46-9452e2c4b670",
      "metadata": {
        "id": "968277ee-c022-4ecc-8b46-9452e2c4b670"
      },
      "source": [
        "## Get the material"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
        "outputId": "5cc7df57-1222-4cf8-b901-ed74c6d600f7",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpu_colab'...\n",
            "remote: Enumerating objects: 374, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 374 (delta 21), reused 27 (delta 10), pack-reused 326\u001b[K\n",
            "Receiving objects: 100% (374/374), 22.34 MiB | 25.87 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggruszczynski/gpu_colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "pjHRMGHu2l4n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHRMGHu2l4n",
        "outputId": "83ba8c3c-91a9-4369-af77-cb1911b3aa9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_colab  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
        "outputId": "a368f384-65fc-4dc5-905d-1052d8c5f106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gpu_colab/code_samples'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd gpu_colab/code_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f",
      "metadata": {
        "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f"
      },
      "source": [
        "## Create a file, compile & run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "pMoR9ZcTXlEQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMoR9ZcTXlEQ",
        "outputId": "a77039cc-011f-47f6-e3a2-64557bd716d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file hello.cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "HaXyn0NFacCN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaXyn0NFacCN",
        "outputId": "18e5e70f-ffe1-444c-e34c-ed3a171d7348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===print working directory and its content===\n",
            "/content\n",
            "gpu_colab\n",
            "hello\n",
            "hello.cpp\n",
            "sample_data\n",
            "===execute the program===\n",
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "g++ hello.cpp -o hello\n",
        "echo \"===print working directory and its content===\"\n",
        "pwd\n",
        "ls\n",
        "echo \"===execute the program===\"\n",
        "./hello"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adUrXDBVdhjh",
      "metadata": {
        "id": "adUrXDBVdhjh"
      },
      "source": [
        "## cpp (auto) magic\n",
        "\n",
        "This section explains how to create a wrapper for your cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "hpCwJPSRd3J1",
      "metadata": {
        "id": "hpCwJPSRd3J1"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "18ty9_RQd41P",
      "metadata": {
        "id": "18ty9_RQd41P"
      },
      "outputs": [],
      "source": [
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Yt-qkdx5d7gP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-qkdx5d7gP",
        "outputId": "042baa51-0f87-4905-a566-d90e4b2ae99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4ccedQXcd-Ph",
      "metadata": {
        "id": "4ccedQXcd-Ph"
      },
      "outputs": [],
      "source": [
        "cpp_header = \"\"\"\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <iterator>\n",
        "#include <utility>\n",
        "#include <map>\n",
        "using namespace std;\n",
        "\"\"\"\n",
        "\n",
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  if ' main()' not in cell:\n",
        "    cell = \"int main(){\" + cell + \"}\"\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cpp_header + cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "EpDK39cDeGeZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpDK39cDeGeZ",
        "outputId": "4282cec6-02da-47af-d9cd-0ba0eab91cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "std::cout << \"Hello World!\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "v6301a-aeHwj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6301a-aeHwj",
        "outputId": "8285df9d-543e-459e-a52e-c43bffffcfb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01234\n",
            "100 lat!\n"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "for(int i=0; i<5; i++) {\n",
        "    cout << i;\n",
        "}\n",
        "\n",
        "cout << endl;\n",
        "pair <int, string> PAIR1;\n",
        "\n",
        "PAIR1.first = 100;\n",
        "PAIR1.second = \"lat!\" ;\n",
        "\n",
        "cout << PAIR1.first << \" \";\n",
        "cout << PAIR1.second << endl;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707",
      "metadata": {
        "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707"
      },
      "source": [
        "# Activate GPU\n",
        "\n",
        "- To get access to a GPU, click on the *Runtime* menu and select *Change runtime type*. Choose GPU as a Hardware accelerator. It might take a minute for your notebook to connect to a GPU.\n",
        "- To check whether a GPU has been connected to your session, run the code cell below with the ``!nvidia-smi`` command by hitting ``SHIFT-ENTER`` on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
        "outputId": "ee6545f5-ad98-4b92-d19f-e41ef23f5499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 28 11:54:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "dOjw-YYKgFAk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOjw-YYKgFAk",
        "outputId": "000b360f-3ec1-4f61-b673-0f7b6499779e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%file hello_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// functions qualifers:\n",
        "// __global__ launched by CPU on device (must return void)\n",
        "// __device__ called from other GPU functions (never CPU)\n",
        "// __host__ can be executed by CPU\n",
        "// (can be used together with __device__)\n",
        "\n",
        "// kernel launch:\n",
        "// f_name<<<blocks,threads_per_block>>>(p1,... pN)\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"-------------------------------\\n\");\n",
        "    dim3 grid_dim(2,1,1);\n",
        "    dim3 block_dim(3,1,1);\n",
        "    print_from_gpu<<<grid_dim, block_dim>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd",
      "metadata": {
        "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd"
      },
      "source": [
        "## Check version of your GPU card\n",
        "if you received an older gpu like Tesla K80 (check the output of `!nvidia-smi` command) add the `-gencode arch=compute_35,code=sm_35` flags to nvcc compiler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "CM8yJ2s6sUF9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM8yJ2s6sUF9",
        "outputId": "745dc338-a02e-4b0d-9b7f-15fb80c44663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from host!\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "-------------------------------\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "CUDA_SUFF=70\n",
        "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./hello_cuda.cu -o hello_cuda\n",
        "./hello_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Um57DFCosVPp",
      "metadata": {
        "id": "Um57DFCosVPp"
      },
      "source": [
        "## if you were lucky to get a more recent gpu (like Tesla T4)...\n",
        "\n",
        "you can install a python wrapper to run `%%cu` cells directly\n",
        "\n",
        "```.sh\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "```\n",
        "\n",
        "then,\n",
        "\n",
        "```\n",
        "%%cu\n",
        "\n",
        "your cell with cuda code...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "_2wOeFnMsFc8",
      "metadata": {
        "id": "_2wOeFnMsFc8",
        "outputId": "f5158299-15e7-4836-b448-9bd6d90832a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9tps1l78\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9tps1l78\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=42f54f9030f39b5f509f78399a34df65fc85f82f87b67dadda675f6a997d1b36\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-km_bcjie/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "XljRG_pmsKir",
      "metadata": {
        "id": "XljRG_pmsKir",
        "outputId": "851d37d2-2060-4d55-9044-0c3940075489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "WEJ5EW8tsBq7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEJ5EW8tsBq7",
        "outputId": "b333b6c2-c8c8-4c53-adff-8c6fb5281f03",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from host!\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "intro_setup.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}