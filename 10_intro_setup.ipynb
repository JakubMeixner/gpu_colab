{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/10_intro_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609",
      "metadata": {
        "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609"
      },
      "source": [
        "# Introduction - Syntax sugar \n",
        "\n",
        "When you run a command with \n",
        "\n",
        "- `!`  it directly executes a bash command in a **subshell**.\n",
        "\n",
        "- `%`  it executes one of the magic commands defined in IPython.\n",
        "\n",
        "- `%% my_native_language` defines the language used to interpret the cell\n",
        "\n",
        "Some of the magic commands defined by IPython deliberately mirror bash commands, but they differ in the implementation details.\n",
        "\n",
        "For example, running the !cd bash command does not persistently change your directory, because it runs in a temporary subshell. However, running the %cd magic command will persistently change your directory:\n",
        "\n",
        "```.sh\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "!cd sample_data/\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "%cd sample_data/\n",
        "!pwd\n",
        "# /content/sample_data\n",
        "```\n",
        "\n",
        "Reference <https://ipython.readthedocs.io/en/stable/interactive/magics.html>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dhrB0IVgfK_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dhrB0IVgfK_",
        "outputId": "b413eb49-959f-4a7f-c822-789fad87d92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 5.43656366 14.7781122  40.17107385]\n",
            "env: MY_VARIABLE=123\n",
            "/content\n",
            "my shell variable 23\n"
          ]
        }
      ],
      "source": [
        "# an example of mixing python an shell in one cell\n",
        "\n",
        "# this is python (default interpreter)\n",
        "import numpy as np\n",
        "print(2*np.exp([1,2,3])) \n",
        "\n",
        "# this is bash shell\n",
        "%env  MY_VARIABLE=123 \n",
        "!pwd\n",
        "!echo \"my shell variable ${123}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968277ee-c022-4ecc-8b46-9452e2c4b670",
      "metadata": {
        "id": "968277ee-c022-4ecc-8b46-9452e2c4b670"
      },
      "source": [
        "## Get the material"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
        "outputId": "cb20e968-1d3b-4e96-cc36-8a434ce5c7e1",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpu_colab'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 75 (delta 28), reused 22 (delta 5), pack-reused 15\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggruszczynski/gpu_colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "pjHRMGHu2l4n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHRMGHu2l4n",
        "outputId": "96df325e-a58e-4819-b6cb-92c7a11c1e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_colab  sample_data\tsrc\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
        "outputId": "8589c07e-98a7-45ae-c10b-d866b8177444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpu_colab/code_samples\n"
          ]
        }
      ],
      "source": [
        "%cd gpu_colab/code_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f",
      "metadata": {
        "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f"
      },
      "source": [
        "## Create a file, compile & run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "pMoR9ZcTXlEQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMoR9ZcTXlEQ",
        "outputId": "8c0291a6-42fb-4410-cb03-7f4d4f46bf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cpp\n"
          ]
        }
      ],
      "source": [
        "%%file hello.cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "HaXyn0NFacCN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaXyn0NFacCN",
        "outputId": "1e23257a-2a86-413e-be72-eb242975672c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===print working directory and its content===\n",
            "/content/gpu_colab/code_samples\n",
            "ex1_hello_world.cu\n",
            "ex2_vector_add.cu\n",
            "ex3_matrix_add.cu\n",
            "ex4_parallel_reduction.cu\n",
            "ex5_thrust_reduction.cu\n",
            "ex6_thrust_saxpy.cu\n",
            "gpu_batch.sh\n",
            "hello\n",
            "hello.cpp\n",
            "hello_thrust.cu\n",
            "===execute the program===\n",
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "g++ hello.cpp -o hello\n",
        "echo \"===print working directory and its content===\"\n",
        "pwd\n",
        "ls\n",
        "echo \"===execute the program===\"\n",
        "./hello"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adUrXDBVdhjh",
      "metadata": {
        "id": "adUrXDBVdhjh"
      },
      "source": [
        "## cpp (auto) magic \n",
        "\n",
        "This section explains how to create a wrapper for your cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "hpCwJPSRd3J1",
      "metadata": {
        "id": "hpCwJPSRd3J1"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "18ty9_RQd41P",
      "metadata": {
        "id": "18ty9_RQd41P"
      },
      "outputs": [],
      "source": [
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Yt-qkdx5d7gP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-qkdx5d7gP",
        "outputId": "8d90847b-0d27-43bc-cb77-e340c8550827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4ccedQXcd-Ph",
      "metadata": {
        "id": "4ccedQXcd-Ph"
      },
      "outputs": [],
      "source": [
        "cpp_header = \"\"\"\n",
        "#include <iostream> \n",
        "#include <string>\n",
        "#include <iterator> \n",
        "#include <utility> \n",
        "#include <map>\n",
        "using namespace std;\n",
        "\"\"\"\n",
        "\n",
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  if ' main()' not in cell:\n",
        "    cell = \"int main(){\" + cell + \"}\"\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cpp_header + cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "EpDK39cDeGeZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpDK39cDeGeZ",
        "outputId": "3303f237-6996-46e2-a34e-800652f7ffa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "std::cout << \"Hello World!\";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "v6301a-aeHwj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6301a-aeHwj",
        "outputId": "c2c6c311-5b0e-4738-ec68-1b88856621b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01234\n",
            "100 lat!\n"
          ]
        }
      ],
      "source": [
        "%%cpp\n",
        "for(int i=0; i<5; i++) {\n",
        "    cout << i;\n",
        "}\n",
        "\n",
        "cout << endl;\n",
        "pair <int, string> PAIR1; \n",
        "\n",
        "PAIR1.first = 100; \n",
        "PAIR1.second = \"lat!\" ; \n",
        "\n",
        "cout << PAIR1.first << \" \"; \n",
        "cout << PAIR1.second << endl; "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707",
      "metadata": {
        "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707"
      },
      "source": [
        "# Activate GPU\n",
        "\n",
        "- To get access to a GPU, click on the *Runtime* menu and select *Change runtime type*. Choose GPU as a Hardware accelerator. It might take a minute for your notebook to connect to a GPU.\n",
        "- To check whether a GPU has been connected to your session, run the code cell below with the ``!nvidia-smi`` command by hitting ``SHIFT-ENTER`` on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
        "outputId": "93020264-707e-41be-ee5b-f8de435f25f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr  8 10:29:06 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dOjw-YYKgFAk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOjw-YYKgFAk",
        "outputId": "c9f598fc-342d-48f9-be84-141b210d47e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_cuda.cu\n"
          ]
        }
      ],
      "source": [
        "%%file hello_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// functions qualifers:\n",
        "// __global__ launched by CPU on device (must return void)\n",
        "// __device__ called from other GPU functions (never CPU)\n",
        "// __host__ can be executed by CPU\n",
        "// (can be used together with __device__)\n",
        "\n",
        "// kernel launch:\n",
        "// f_name<<<blocks,threads_per_block>>>(p1,... pN)\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"-------------------------------\\n\");\n",
        "    dim3 grid_dim(2,1,1);\n",
        "    dim3 block_dim(3,1,1);\n",
        "    print_from_gpu<<<grid_dim, block_dim>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd",
      "metadata": {
        "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd"
      },
      "source": [
        "## Check version of your GPU card\n",
        "if you received an older gpu like Tesla K80 (check the output of `!nvidia-smi` command) add the `-gencode arch=compute_35,code=sm_35` flags to nvcc compiler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "CM8yJ2s6sUF9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM8yJ2s6sUF9",
        "outputId": "d0482107-f56b-4ec4-c648-c271fd92d56a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from host!\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "-------------------------------\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "CUDA_SUFF=35\n",
        "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./hello_cuda.cu -o hello_cuda\n",
        "./hello_cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Um57DFCosVPp",
      "metadata": {
        "id": "Um57DFCosVPp"
      },
      "source": [
        "## if you were lucky to get a more recent gpu (like Tesla T4)...\n",
        "\n",
        "you can install a python wrapper to run `%%cu` cells directly\n",
        "\n",
        "```.sh\n",
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "```\n",
        "\n",
        "then,\n",
        "\n",
        "```\n",
        "%%cu \n",
        "\n",
        "your cell with cuda code...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "_2wOeFnMsFc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2wOeFnMsFc8",
        "outputId": "8f93e9ee-4554-4ecc-c59d-535a0a71a65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-szmf90vm\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-szmf90vm\n"
          ]
        }
      ],
      "source": [
        "%pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "XljRG_pmsKir",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XljRG_pmsKir",
        "outputId": "f63ceeb5-ddd1-49af-8944-22a546e4c8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WEJ5EW8tsBq7",
      "metadata": {
        "id": "WEJ5EW8tsBq7"
      },
      "outputs": [],
      "source": [
        "%%cu \n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "intro_setup.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}