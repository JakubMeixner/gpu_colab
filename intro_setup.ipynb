{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/intro_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609",
      "metadata": {
        "id": "dfc3df1f-7fd3-4e76-80e6-e45c09142609"
      },
      "source": [
        "# Introduction - Syntax sugar \n",
        "\n",
        "When you run a command with \n",
        "\n",
        "- `!`  it directly executes a bash command in a **subshell**.\n",
        "\n",
        "- `%`  it executes one of the magic commands defined in IPython.\n",
        "\n",
        "- `%% my_native_language` defines the language used to interpret the cell\n",
        "\n",
        "Some of the magic commands defined by IPython deliberately mirror bash commands, but they differ in the implementation details.\n",
        "\n",
        "For example, running the !cd bash command does not persistently change your directory, because it runs in a temporary subshell. However, running the %cd magic command will persistently change your directory:\n",
        "\n",
        "```.sh\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "!cd sample_data/\n",
        "!pwd\n",
        "# /content\n",
        "\n",
        "%cd sample_data/\n",
        "!pwd\n",
        "# /content/sample_data\n",
        "```\n",
        "\n",
        "Reference <https://ipython.readthedocs.io/en/stable/interactive/magics.html>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an example of mixing python an shell in one cell\n",
        "\n",
        "# this is python (default interpreter)\n",
        "import numpy as np\n",
        "print(2*np.exp([1,2,3])) \n",
        "\n",
        "# this is bash shell\n",
        "%env  MY_VARIABLE=123 \n",
        "!pwd\n",
        "!echo \"my shell variable ${123}\""
      ],
      "metadata": {
        "id": "5dhrB0IVgfK_",
        "outputId": "b413eb49-959f-4a7f-c822-789fad87d92a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5dhrB0IVgfK_",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 5.43656366 14.7781122  40.17107385]\n",
            "env: MY_VARIABLE=123\n",
            "/content\n",
            "my shell variable 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968277ee-c022-4ecc-8b46-9452e2c4b670",
      "metadata": {
        "id": "968277ee-c022-4ecc-8b46-9452e2c4b670"
      },
      "source": [
        "## Get the material"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f666f00-6d5f-4253-be63-a2a21bb56287",
        "outputId": "84bb956a-575c-4d21-94e1-82baa8437d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gpu_colab' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggruszczynski/gpu_colab.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjHRMGHu2l4n",
        "outputId": "982ec752-1845-4145-8815-1675f05e1eb7"
      },
      "id": "pjHRMGHu2l4n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_colab  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191a4b9d-76a7-45fe-84e1-3a7ecb5f0b09",
        "outputId": "1ecd3178-f6a2-4d10-b55b-97974fb7faad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpu_colab/code_samples\n"
          ]
        }
      ],
      "source": [
        "% cd gpu_colab/code_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f",
      "metadata": {
        "id": "f45c6945-c7b0-4877-aadb-9ab4f01b814f"
      },
      "source": [
        "## Create a file, compile & run!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hello.cpp\n",
        "#include <iostream>\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "pMoR9ZcTXlEQ",
        "outputId": "d72181d7-5190-4c07-a854-c5b78c51a18f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pMoR9ZcTXlEQ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "g++ hello.cpp -o hello\n",
        "echo \"===print working directory and its content===\"\n",
        "pwd\n",
        "ls\n",
        "echo \"===execute the program===\"\n",
        "./hello"
      ],
      "metadata": {
        "id": "HaXyn0NFacCN",
        "outputId": "6660bcc0-51d1-4d36-c65b-51afc817d9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HaXyn0NFacCN",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===print working directory and its content===\n",
            "/content\n",
            "hello  hello.cpp  sample_data\n",
            "===execute the program===\n",
            "Hello World!"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cpp (auto) magic \n",
        "\n",
        "This section explains how to create a wrapper for your cell."
      ],
      "metadata": {
        "id": "adUrXDBVdhjh"
      },
      "id": "adUrXDBVdhjh"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magic import register_cell_magic"
      ],
      "metadata": {
        "id": "hpCwJPSRd3J1"
      },
      "id": "hpCwJPSRd3J1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ],
      "metadata": {
        "id": "18ty9_RQd41P"
      },
      "id": "18ty9_RQd41P",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cpp\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"Hello World!\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "Yt-qkdx5d7gP",
        "outputId": "1c8a05a8-8b0c-452a-de74-826800390ff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Yt-qkdx5d7gP",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_header = \"\"\"\n",
        "#include <iostream> \n",
        "#include <string>\n",
        "#include <iterator> \n",
        "#include <utility> \n",
        "#include <map>\n",
        "using namespace std;\n",
        "\"\"\"\n",
        "\n",
        "@register_cell_magic\n",
        "def cpp(line, cell):\n",
        "  if ' main()' not in cell:\n",
        "    cell = \"int main(){\" + cell + \"}\"\n",
        "  with open('a.cpp', 'w') as f:\n",
        "    f.write(cpp_header + cell)\n",
        "  !g++ a.cpp\n",
        "  !./a.out"
      ],
      "metadata": {
        "id": "4ccedQXcd-Ph"
      },
      "id": "4ccedQXcd-Ph",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cpp\n",
        "std::cout << \"Hello World!\";"
      ],
      "metadata": {
        "id": "EpDK39cDeGeZ",
        "outputId": "d7a9a1ab-15b6-4139-c98d-0f71bb888da6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EpDK39cDeGeZ",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cpp\n",
        "for(int i=0; i<5; i++) {\n",
        "    cout << i;\n",
        "}\n",
        "\n",
        "cout << endl;\n",
        "pair <int, string> PAIR1; \n",
        "\n",
        "PAIR1.first = 100; \n",
        "PAIR1.second = \"lat!\" ; \n",
        "\n",
        "cout << PAIR1.first << \" \"; \n",
        "cout << PAIR1.second << endl; "
      ],
      "metadata": {
        "id": "v6301a-aeHwj",
        "outputId": "c9acde83-edb6-428f-ee64-64aa0a5c6169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v6301a-aeHwj",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01234\n",
            "100 lat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707",
      "metadata": {
        "id": "a2149e37-fab1-43f1-9ac8-8e7f81c57707"
      },
      "source": [
        "# Activate GPU\n",
        "\n",
        "- To get access to a GPU, click on the *Runtime* menu and select *Change runtime type*. Choose GPU as a Hardware accelerator. It might take a minute for your notebook to connect to a GPU.\n",
        "- To check whether a GPU has been connected to your session, run the code cell below with the ``!nvidia-smi`` command by hitting ``SHIFT-ENTER`` on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6c6f23a-d333-409b-b254-f3bc120d425d",
        "outputId": "103c6174-f72d-455a-ecd4-28b971143354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 23 16:07:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file hello_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// functions qualifers:\n",
        "// __global__ launched by CPU on device (must return void)\n",
        "// __device__ called from other GPU functions (never CPU)\n",
        "// __host__ can be executed by CPU\n",
        "// (can be used together with __device__)\n",
        "\n",
        "// kernel launch:\n",
        "// f_name<<<blocks,threads_per_block>>>(p1,... pN)\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    printf(\"-------------------------------\\n\");\n",
        "    dim3 grid_dim(2,1,1);\n",
        "    dim3 block_dim(3,1,1);\n",
        "    print_from_gpu<<<grid_dim, block_dim>>>();  // <<<blocks, threads_per_block>>>\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "dOjw-YYKgFAk",
        "outputId": "849b6f4f-a50b-4dea-b281-87595f734c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dOjw-YYKgFAk",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd",
      "metadata": {
        "id": "c5a883dc-df24-4b1b-9383-11d9a35572dd"
      },
      "source": [
        "## Check version of your GPU card\n",
        "if you received an older gpu like Tesla K80 (check the output of `!nvidia-smi` command) add the `-gencode arch=compute_35,code=sm_35` flags to nvcc compiler."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "CUDA_SUFF=35\n",
        "nvcc -gencode arch=compute_${CUDA_SUFF},code=sm_${CUDA_SUFF} ./hello_cuda.cu -o hello_cuda\n",
        "./hello_cuda"
      ],
      "metadata": {
        "id": "CM8yJ2s6sUF9",
        "outputId": "e3ca9a9c-ff46-4d6a-ce5c-4c6eff3df473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CM8yJ2s6sUF9",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "Hello World from host!\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "-------------------------------\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## if you were lucky to get a more recent gpu (like Tesla T4)...\n",
        "\n",
        "you can install a python wrapper to run `%%cu` cells directly\n",
        "\n",
        "```.sh\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n",
        "```\n",
        "\n",
        "then,\n",
        "\n",
        "```\n",
        "%%cu \n",
        "\n",
        "your cell with cuda code...\n",
        "```\n"
      ],
      "metadata": {
        "id": "Um57DFCosVPp"
      },
      "id": "Um57DFCosVPp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "id": "_2wOeFnMsFc8",
        "outputId": "0f4338e9-ba63-4a56-b871-70b7299b1add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_2wOeFnMsFc8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_3ffnuc8\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_3ffnuc8\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4306 sha256=2627b2ba182e1c4d80f1730d4ad56d3341189b94129e76757038fb94cc338094\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0kz88oe7/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "id": "XljRG_pmsKir",
        "outputId": "f4a45c8a-1140-4872-aeb4-930b0629e333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XljRG_pmsKir",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu \n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void print_from_gpu(void) {\n",
        "    int tidx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    printf(\"Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> %d = %d * %d + %d \\n\",\n",
        "    tidx, blockIdx.x, blockDim.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    printf(\"Hello World from host!\\n\");\n",
        "\n",
        "    print_from_gpu<<<2,3>>>();  // <<<blocks, threads_per_block>>>\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "WEJ5EW8tsBq7",
        "outputId": "22679a9b-842c-427e-8833-66d058c3e874",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WEJ5EW8tsBq7",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from host!\n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 0 = 0 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 1 = 0 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 2 = 0 * 3 + 2 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 3 = 1 * 3 + 0 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 4 = 1 * 3 + 1 \n",
            "Hello from device! My threadId = blockIdx.x *blockDim.x + threadIdx.x <=> 5 = 1 * 3 + 2 \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "intro_setup.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}