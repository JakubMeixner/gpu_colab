{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdTG75vmQln6fCE/X3FJBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggruszczynski/gpu_colab/blob/main/80_gpu_aos_vs_soa_mem_layout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80fYwvaihxY0",
        "outputId": "15cb1bdf-c4f6-465d-ee5a-5fad735fdda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 30 12:16:53 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "from numba import jit\n",
        "import numpy as np\n",
        "import math\n",
        "from numba import vectorize, int8, int32, int64, float32, float64\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.set_printoptions(precision=1, suppress=True)\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "M = 2**13     # ~1000MB \n",
        "# M = 2**10   # ~10MB works better with SOA\n",
        "# M = 2**6    # <1MB, no difference\n",
        "\n",
        "N = 3*M**2\n",
        "\n",
        "a = np.arange(N, dtype=np.float64) # [0...N] on the host\n",
        "print(f\"Total number of elements: {N} \\nDimensions of the matrix MxM: {M} \\nMemory size of array in [MB]: {a.nbytes/1E6}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCNRnP5xh26B",
        "outputId": "ed72350c-b6f9-43ec-e40a-cb0fd9b85994"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of elements: 201326592 \n",
            "Dimensions of the matrix MxM: 8192 \n",
            "Memory size of array in [MB]: 1610.612736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threadsperblock = (32,32)\n",
        "blockspergrid_x = math.ceil(M / threadsperblock[0])\n",
        "blockspergrid_y = math.ceil(M / threadsperblock[1])\n",
        "# blockspergrid_z = math.ceil(d_a.shape[2] / threadsperblock[2])\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "total_threads_in_block = threadsperblock[0]*threadsperblock[1]\n",
        "assert total_threads_in_block <= 1024 # hardware limit\n",
        "assert total_threads_in_block <= M # avoid useless threads\n",
        "\n",
        "print(f\"Blockspergrid: {blockspergrid}, Total number of threads in a block: {total_threads_in_block}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvacfqFtkxvn",
        "outputId": "8de6a9d0-db90-4ad9-f477-a720f766a12f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blockspergrid: (256, 256), Total number of threads in a block: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AOS"
      ],
      "metadata": {
        "id": "Uln1RQRirPjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_aos = a.reshape(M,M,3)        # The MxM matrix stores Points(x,y,z) in its most inner dimension\n",
        "aos_out = np.zeros_like(arr_aos)\n",
        "print(f\" Shape: {arr_aos.shape} \\n Strides {arr_aos.strides} \\n Content {arr_aos[0,0:3,:]}\")\n",
        "\n",
        "d_arr_aos = cuda.to_device(arr_aos)           # Copy array from host to the device\n",
        "d_aos_out = cuda.device_array_like(d_arr_aos) # preallocate an arracy filled with 0\n",
        "\n",
        "# print(f\"GPU result:\\n {d_aos_out.copy_to_host()[0,0:3,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VQD-8LmiBCs",
        "outputId": "406c0e13-4fd0-405d-a73f-db6d9e6e6f44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape: (8192, 8192, 3) \n",
            " Strides (196608, 24, 8) \n",
            " Content [[0. 1. 2.]\n",
            " [3. 4. 5.]\n",
            " [6. 7. 8.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cpu_aos(M, A_in,  A_out):    \n",
        "    for tidx in range(M):\n",
        "      for tidy in range(M):\n",
        "        A_out[tidx][tidy][2] = A_in[tidx][tidy][2] + 1000\n",
        "\n",
        "@cuda.jit\n",
        "def kernel_gpu_aos(M, A_in, A_out):\n",
        "    tidx, tidy = cuda.grid(2)\n",
        "    # The above is equivalent to the following 2 lines of code:\n",
        "    # x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    # y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "    \n",
        "    # loop over all points in domain (except boundary)\n",
        "    if (tidx < M and tidy < M):\n",
        "        A_out[tidx][tidy][2] = A_in[tidx][tidy][2] + 1000"
      ],
      "metadata": {
        "id": "hbO3ERQ8izdI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit kernel_gpu_aos[blockspergrid, threadsperblock](M, d_arr_aos, d_aos_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_hI52-pkCZM",
        "outputId": "596aeaa9-9c96-48a9-e385-ff5bf87532bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.6 ms ± 34 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %timeit  \n",
        "# cpu_aos(M, arr_aos, aos_out) #to slow"
      ],
      "metadata": {
        "id": "x8htVlgVmFis"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"CPU result:\\n {aos_out[0,0:3,:]}\")\n",
        "print(f\"GPU result:\\n {d_aos_out.copy_to_host()[0,0:3,:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDd3pDZUp1yC",
        "outputId": "23017a24-9ec4-4eb5-fd97-4aaef08cd68c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU result:\n",
            " [[   0.    0. 1002.]\n",
            " [   0.    0. 1005.]\n",
            " [   0.    0. 1008.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup"
      ],
      "metadata": {
        "id": "pDTTeOBArUEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del arr_aos\n",
        "del aos_out\n",
        "\n",
        "del d_arr_aos\n",
        "del d_aos_out"
      ],
      "metadata": {
        "id": "gcPBw2whrV-e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SOA\n"
      ],
      "metadata": {
        "id": "wEC6wPRLrKC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_soa = a.reshape(3,M,M)                     # Each of the most outer dimensions stores a MxM matrix, which contains all x, y or z coordinates.\n",
        "out_soa = np.zeros_like(arr_soa)\n",
        "\n",
        "print(f\" Shape: {arr_soa.shape} \\n Strides {arr_soa.strides} \\n Content {arr_soa[2,0,:10]}\")\n",
        "\n",
        "d_arr_soa = cuda.to_device(arr_soa)            # Copy array from host to the device\n",
        "d_soa_out = cuda.device_array_like(d_arr_soa)  # preallocate an arracy filled with 0"
      ],
      "metadata": {
        "id": "gat73fHNo3U4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35a4a87-eee7-46a5-94a4-e6931a3262fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Shape: (3, 8192, 8192) \n",
            " Strides (536870912, 65536, 8) \n",
            " Content [1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08\n",
            " 1.3e+08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cpu_soa(M, A_in,  A_out):    \n",
        "    for tidx in range(M):\n",
        "      for tidy in range(M):\n",
        "        A_out[2][tidx][tidy] = A_in[2][tidx][tidy] + 1000\n",
        "\n",
        "@cuda.jit\n",
        "def kernel_gpu_soa(M, A_in,  A_out):\n",
        "    tidx, tidy = cuda.grid(2)\n",
        "    # The above is equivalent to the following 2 lines of code:\n",
        "    # x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    # y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "    \n",
        "    # loop over all points in domain (except boundary)\n",
        "    if (tidx < M and tidy < M):\n",
        "       A_out[2][tidx][tidy] = A_in[2][tidx][tidy] + 1000"
      ],
      "metadata": {
        "id": "L8pMe3CHmPMR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit kernel_gpu_soa[blockspergrid, threadsperblock](M, d_arr_soa, d_soa_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbCeO19HpRdk",
        "outputId": "456434ce-2c74-467b-8bc6-8c2fa1ac45ab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.7 ms ± 79.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %timeit \n",
        "# cpu_soa(M, arr_soa, out_soa)  #to slow"
      ],
      "metadata": {
        "id": "QfIKS9onl-Cj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"CPU result:\\n {out_soa[2,0,:10]}\")\n",
        "print(f\"GPU result:\\n {d_soa_out.copy_to_host()[2,0,:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iJhdOa5l-fF",
        "outputId": "6dc03cd2-1090-4c9a-dde5-4a14cdbbeca6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU result:\n",
            " [1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08 1.3e+08\n",
            " 1.3e+08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleanup"
      ],
      "metadata": {
        "id": "m40dapYIy4nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del arr_soa\n",
        "del out_soa\n",
        "\n",
        "del d_arr_soa\n",
        "del d_soa_out"
      ],
      "metadata": {
        "id": "Q-efEasAywsE"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}